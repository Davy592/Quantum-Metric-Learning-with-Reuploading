{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.533159Z",
     "start_time": "2025-02-25T12:56:28.526193Z"
    }
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, QuantumRegister\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sklearn.metrics.cluster as cluster_metrics\n",
    "import numpy as np\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "from sklearn.manifold import TSNE\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "import torch\n",
    "from torch import nn\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.583214Z",
     "start_time": "2025-02-25T12:56:28.573346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set all needed seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility\n",
    "    Args:\n",
    "        seed (int): Seed value\n",
    "    \"\"\"\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # CUDA deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Qiskit determinism\n",
    "    algorithm_globals.random_seed = seed\n",
    "    \n",
    "    # Environment variables\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.663103Z",
     "start_time": "2025-02-25T12:56:28.658970Z"
    }
   },
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(\"CUDA Available:  \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using {color.BOLD} {str(device).upper()} {color.END} Acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.687986Z",
     "start_time": "2025-02-25T12:56:28.685260Z"
    }
   },
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = cluster_metrics.contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "def evaluate_clustering(X, pred_y, true_y):\n",
    "    print(f\"{'Silhouette:':15s}{silhouette_score(X, pred_y):2.3f}\")\n",
    "    print(f\"{'Purity:':15s}{purity_score(true_y, pred_y):2.3f}\")\n",
    "\n",
    "def evaluate_clustering_table(X, pred_y, true_y):\n",
    "    return silhouette_score(X, pred_y), purity_score(true_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.788896Z",
     "start_time": "2025-02-25T12:56:28.713256Z"
    }
   },
   "outputs": [],
   "source": [
    "INITIAL_TRAINING_SAMPLES = 400\n",
    "\n",
    "\n",
    "MNIST_base_transform = transforms.Compose([\n",
    "transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "MNIST_dataset_train = datasets.MNIST(root=\"quantum_metric_learning-master/data/dataset/MNIST\", train=True, download=True, transform=MNIST_base_transform)\n",
    "MNIST_dataset_test = datasets.MNIST(root=\"quantum_metric_learning-master/data/dataset/MNIST\", train=False, download=True, transform=MNIST_base_transform)\n",
    "\n",
    "\n",
    "if False:\n",
    "    index01 = MNIST_dataset_train.train_labels <= 1\n",
    "    MNIST_dataset_train.data = MNIST_dataset_train.data[index01]\n",
    "    MNIST_dataset_train.targets = MNIST_dataset_train.targets[index01]\n",
    "\n",
    "    index01_test = MNIST_dataset_test.train_labels <= 1\n",
    "    MNIST_dataset_test.data = MNIST_dataset_test.data[index01_test]\n",
    "    MNIST_dataset_test.targets = MNIST_dataset_test.targets[index01_test]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"FULL DATASET INFO\")\n",
    "print(f\"Image shape            : {MNIST_dataset_train.data.shape}\")\n",
    "print(f\"Total training samples : {len(MNIST_dataset_train)}\")\n",
    "print(f\"Total test     samples : {len(MNIST_dataset_test)}\")\n",
    "print(\"\")\n",
    "\n",
    "init_train_data, _, init_train_target, _ = train_test_split(\n",
    "    range(len(MNIST_dataset_train)), \n",
    "    MNIST_dataset_train.targets,\n",
    "    random_state=42,\n",
    "    stratify=MNIST_dataset_train.targets,\n",
    "    test_size=len(MNIST_dataset_train)- INITIAL_TRAINING_SAMPLES)\n",
    "\n",
    "\n",
    "X = MNIST_dataset_train.data[init_train_data].numpy().astype(\"float32\") / 255\n",
    "y = MNIST_dataset_train.targets[init_train_data].numpy().astype(\"float32\") \n",
    "\n",
    "print(\"TRAINING DATA INFO\")\n",
    "print(f\"Image shape            : {X.shape}\")\n",
    "print(f\"Total training samples : {len(X)}\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "'''\n",
    "init_test_data, _, init_test_target, _ = train_test_split(\n",
    "    range(len(MNIST_dataset_test)), \n",
    "    MNIST_dataset_test.targets,\n",
    "    random_state=42,\n",
    "    stratify=MNIST_dataset_test.targets,\n",
    "    test_size=len(MNIST_dataset_test)- INITIAL_TESTING_SAMPLES)\n",
    "'''\n",
    "\n",
    "X_test = MNIST_dataset_test.data.numpy().astype(\"float32\") / 255\n",
    "y_test = MNIST_dataset_test.targets.numpy().astype(\"float32\")\n",
    "\n",
    "print(\"TESTING DATA INFO\")\n",
    "print(f\"Image shape            : {X_test.shape}\")\n",
    "print(f\"Total training samples : {len(X_test)}\")\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.817718Z",
     "start_time": "2025-02-25T12:56:28.813326Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNIST_Distance_Dataset_Triplet_Loss(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.kers = np.ones((self.data.shape[0], self.data.shape[0]))\n",
    "        self.output_transform = transforms.ToTensor()\n",
    "        self.len = len(self.target)\n",
    "        self.classes = {i:(np.where(self.target == i)[0], np.where(self.target != i)[0] ) for i in range(10)}\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_anchor(idx), self.get_positive(idx), self.get_negative(idx)\n",
    "    \n",
    "    def get_anchor(self, idx):\n",
    "        return self.output_transform(self.data[idx])\n",
    "    \n",
    "\n",
    "    def get_positive(self, idx):\n",
    "        i = np.random.choice(self.classes[self.target[idx]][0])\n",
    "        return self.output_transform(self.data[i])\n",
    "    \n",
    "    def get_negative(self, idx):\n",
    "        i = np.random.choice(self.classes[self.target[idx]][1])\n",
    "        return self.output_transform(self.data[i])\n",
    "\n",
    "\n",
    "    def get_order(self):\n",
    "        return self.target.argsort()\n",
    "\n",
    "\n",
    "    def ordered_pairwise(self):\n",
    "        return self.kers[:,self.get_order()][self.get_order(),:]\n",
    "\n",
    "\n",
    "    def get_flatten(self):\n",
    "        return self.data.reshape((self.data.shape[0], self.data.shape[1]**2))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:28.973983Z",
     "start_time": "2025-02-25T12:56:28.842175Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "t = MNIST_Distance_Dataset_Triplet_Loss(X_train, y_train)\n",
    "v = MNIST_Distance_Dataset_Triplet_Loss(X_val, y_val)\n",
    "#stampa lunghezza del dataset\n",
    "\n",
    "print(len(t))\n",
    "print(len(v))\n",
    "\n",
    "anchor, pos, neg = t[0]\n",
    "\n",
    "\n",
    "plt.matshow(anchor.squeeze(0))\n",
    "plt.matshow(pos.squeeze(0))\n",
    "plt.matshow(neg.squeeze(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:29.874119Z",
     "start_time": "2025-02-25T12:56:29.004013Z"
    }
   },
   "outputs": [],
   "source": [
    "reduction_model = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "\n",
    "vis_x = reduction_model.fit_transform(t.get_flatten(), t.target)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(\"Data visualization using TSNE\", weight=\"bold\")\n",
    "ax.scatter(vis_x[:,0], vis_x[:,1], c=t.target, cmap='Dark2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIRCUITS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:29.992265Z",
     "start_time": "2025-02-25T12:56:29.919089Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Amplitude encoding, richiede nlog2 features\n",
    "'''\n",
    "def amplitude_encoding(n_features, param_name):\n",
    "  qc = RawFeatureVector(n_features)\n",
    "  qc = qc.assign_parameters(ParameterVector(param_name, n_features))\n",
    "  qc.name = f\"Amplitude Encoding {param_name}\"\n",
    "  return qc\n",
    "\n",
    "\n",
    "def yz_angles_encoding(n_features, param_name):\n",
    "  params = ParameterVector(param_name, n_features)\n",
    "  n_qubit = math.floor(n_features /2) + (1 if (n_features % 2) != 0 else 0)\n",
    "  qc = QuantumCircuit(n_qubit, name=f\"Angles Encoding {param_name}\")\n",
    "  gates = [qc.ry, qc.rz]\n",
    "\n",
    "  for i in range(n_qubit):\n",
    "    for gate_i in range(2):\n",
    "      pindex = i*2 + gate_i\n",
    "      if pindex < n_features:\n",
    "        gates[gate_i](params[pindex], i)\n",
    "\n",
    "  return qc\n",
    "\n",
    "def pooling_layer(in_lane, param_prefix=\"pool\"):\n",
    "  qc = QuantumCircuit(in_lane, name=\"Pooling Layer\")\n",
    "  params = ParameterVector(param_prefix, length=in_lane //2 *3)\n",
    "\n",
    "  for i in range(in_lane//2):\n",
    "    current = i\n",
    "    aux = i+ in_lane//2\n",
    "\n",
    "    base_param =  current*(in_lane//2 -1)\n",
    "\n",
    "    qc.rz(-np.pi/2, aux)\n",
    "    qc.cx(aux, current)\n",
    "    qc.rz(params[base_param + 0], current)\n",
    "    qc.ry(params[base_param + 1], aux)\n",
    "    qc.cx(current, aux)\n",
    "    qc.ry(params[base_param + 2], aux)\n",
    "\n",
    "  return qc\n",
    "\n",
    "\n",
    "\n",
    "pooling_layer(4, param_prefix=\"m\").draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIFICHE ENCODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.053492Z",
     "start_time": "2025-02-25T12:56:30.006800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Modifiche PROF\n",
    "def hRyRx_encoding(n_features):\n",
    "  # qubits\n",
    "  n_qubits = math.floor(n_features /2) + (1 if (n_features % 2) != 0 else 0)\n",
    "  # feature extracted from neural network\n",
    "  n_feature = n_features\n",
    "  feature_map = QuantumCircuit(n_qubits)\n",
    "  input_params = ParameterVector(name='x', length=n_feature)\n",
    "  idx = 0\n",
    "  for i in range(n_qubits):\n",
    "      feature_map.h(i)\n",
    "      feature_map.ry(input_params[idx], i)\n",
    "      feature_map.rx(input_params[idx+1], i)\n",
    "      idx +=2\n",
    "\n",
    "  return feature_map\n",
    "\n",
    "hRyRx_encoding(8).draw(output=\"mpl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.119520Z",
     "start_time": "2025-02-25T12:56:30.076547Z"
    }
   },
   "outputs": [],
   "source": [
    "def hRyRz_encoding(n_features):\n",
    "  # qubits\n",
    "  n_qubits = math.floor(n_features /2) + (1 if (n_features % 2) != 0 else 0)\n",
    "  # feature extracted from neural network\n",
    "  n_feature = n_features\n",
    "  feature_map = QuantumCircuit(n_qubits)\n",
    "  input_params = ParameterVector(name='x', length=n_feature)\n",
    "  idx = 0\n",
    "  for i in range(n_qubits):\n",
    "      feature_map.h(i)\n",
    "      feature_map.ry(input_params[idx], i)\n",
    "      feature_map.rz(input_params[idx+1], i)\n",
    "      idx +=2\n",
    "  return feature_map\n",
    "\n",
    "hRyRz_encoding(8).draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.164126Z",
     "start_time": "2025-02-25T12:56:30.141247Z"
    }
   },
   "outputs": [],
   "source": [
    "amplitude_encoding(4, \"a\").draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.223269Z",
     "start_time": "2025-02-25T12:56:30.186333Z"
    }
   },
   "outputs": [],
   "source": [
    "yz_angles_encoding(8, param_name=\"x\").draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.274547Z",
     "start_time": "2025-02-25T12:56:30.244645Z"
    }
   },
   "outputs": [],
   "source": [
    "def x_angles_encoding(n_features, param_name):\n",
    "  params = ParameterVector(param_name, n_features)\n",
    "  n_qubit = n_features\n",
    "  qc = QuantumCircuit(n_qubit, name=f\"Angles Encoding {param_name}\")\n",
    "  \n",
    "\n",
    "  for i in range(n_qubit):\n",
    "    qc.rx(params[i], i)\n",
    "\n",
    "  return qc\n",
    "\n",
    "x_angles_encoding(4, \"a\").draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding RyRx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.334691Z",
     "start_time": "2025-02-25T12:56:30.295202Z"
    }
   },
   "outputs": [],
   "source": [
    "def RyRx_encoding(n_features): \n",
    "# qubits\n",
    "   n_qubits = math.floor(n_features /2) + (1 if (n_features % 2) != 0 else 0)\n",
    "   # feature extracted from neural network\n",
    "   n_feature = n_features\n",
    "   feature_map = QuantumCircuit(n_qubits)\n",
    "   input_params = ParameterVector(name='x', length=n_feature)\n",
    "   idx = 0\n",
    "   for i in range(n_qubits):\n",
    "      feature_map.ry(input_params[idx], i)\n",
    "      feature_map.rx(input_params[idx+1], i)\n",
    "      idx +=2\n",
    "   return feature_map\n",
    "\n",
    "RyRx_encoding(8).draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSOR NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.360308Z",
     "start_time": "2025-02-25T12:56:30.357268Z"
    }
   },
   "outputs": [],
   "source": [
    "def MPS(num_qubits,parameter_prefix=\"x\", **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Matrix Product State (MPS) quantum circuit.\n",
    "\n",
    "    Args:\n",
    "        num_qubits (int): The number of qubits in the circuit.\n",
    "        **kwargs: Additional keyword arguments to be passed to the \n",
    "        RealAmplitudes.\n",
    "\n",
    "    Returns:\n",
    "        QuantumCircuit: The constructed MPS quantum circuit.\n",
    "        \n",
    "    \"\"\"\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qubits = range(num_qubits)\n",
    "    for i, j in zip(qubits[:-1], qubits[1:]):\n",
    "        block = RealAmplitudes(2, parameter_prefix=f\"{parameter_prefix}_{i},{j}\", **kwargs)\n",
    "        qc.compose(block, [i, j], inplace=True)\n",
    "        qc.barrier()\n",
    "    return qc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definizione del circuito originale ( Con RealAmplitudes + Pooling)\n",
    "\n",
    "### Decommentare l'encoding necessario per poter effettuare gli esperimenti opportuni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.614644Z",
     "start_time": "2025-02-25T12:56:30.458515Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = yz_angles_encoding(8, param_name=\"e\")\n",
    "#encoding = hRyRx_encoding(8)\n",
    "#encoding= hRyRz_encoding(8)\n",
    "#encoding = RyRx_encoding(8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ansatz = QuantumCircuit(4)\n",
    "ansatz.barrier()\n",
    "############################2#######################\n",
    "ansatz = ansatz.compose(RealAmplitudes(num_qubits=4, reps=1, name=\"Layer1\", parameter_prefix=\"l1\"))\n",
    "ansatz.barrier()\n",
    "############################3#######################\n",
    "ansatz = ansatz.compose(pooling_layer(4, \"pool2\"))\n",
    "ansatz.barrier()\n",
    "############################4#######################\n",
    "ansatz = ansatz.compose(RealAmplitudes(num_qubits=2, reps=1, name=\"Layer2\",parameter_prefix=\"l2\"), qubits=[2,3])\n",
    "ansatz.barrier()\n",
    "\n",
    "ansatz.decompose().draw(output=\"mpl\")\n",
    "\n",
    "\n",
    "qnn = QuantumCircuit(4).compose(encoding).compose(ansatz)\n",
    "\n",
    "display(qnn.decompose().draw(\"mpl\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIRCUITO CON TN ( solo MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:30.961808Z",
     "start_time": "2025-02-25T12:56:30.841723Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = yz_angles_encoding(8, param_name=\"e\")\n",
    "\n",
    "\n",
    "qnn = QuantumCircuit(4).compose(encoding)\n",
    "\n",
    "# Aggiunta dell'MPS al circuito\n",
    "ansatz = MPS(num_qubits=4, parameter_prefix=\"mps\")\n",
    "qnn = qnn.compose(ansatz)\n",
    "\n",
    "# Visualizzazione del circuito\n",
    "display(qnn.decompose().draw(\"mpl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definizione Rete Ibrida\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:31.787845Z",
     "start_time": "2025-02-25T12:56:31.753308Z"
    }
   },
   "outputs": [],
   "source": [
    "from qiskit.primitives import Sampler\n",
    "def parity(x):\n",
    "    return f\"{bin(x)}\".count(\"1\")\n",
    "\n",
    "\n",
    "\n",
    "qmodel_1 = SamplerQNN(\n",
    "    circuit=qnn,\n",
    "    input_params=encoding.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    input_gradients=True\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HybridRegressorConvNet(nn.Module):\n",
    "    def __init__(self, qm1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(5,5)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5,5)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.reduction = nn.Sequential(\n",
    "            nn.Linear(in_features=576, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=8)\n",
    "        )\n",
    "     \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=16),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.q1 = TorchConnector(qm1)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.reduction(x)\n",
    "\n",
    "        #Per encoding con HRyRz\n",
    "        #x = x * (math.pi / 2)\n",
    "        #x= self.q1(x)\n",
    "        \n",
    "        x = self.q1(x) * 100\n",
    "\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "distance_model = HybridRegressorConvNet(qmodel_1)\n",
    "distance_model = distance_model.to(\"cpu\")\n",
    "summary(distance_model, input_size=(1,28,28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:31.830824Z",
     "start_time": "2025-02-25T12:56:31.827162Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_model = HybridRegressorConvNet(qmodel_1)\n",
    "training_dataloader = DataLoader(t, batch_size=10, shuffle=True)\n",
    "val_data_loader = DataLoader(v, batch_size=10, shuffle=True)\n",
    "distance_model = distance_model.to(torch.device(\"cpu\"))\n",
    "optimizer = torch.optim.SGD(distance_model.parameters(), lr=1e-2)\n",
    "loss = torch.nn.TripletMarginLoss(margin=2)\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:31.928352Z",
     "start_time": "2025-02-25T12:56:31.855516Z"
    }
   },
   "outputs": [],
   "source": [
    "qmodel_1.circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:31.954138Z",
     "start_time": "2025-02-25T12:56:31.950554Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, optimizer, criterion, train_data_loader, val_data_loader, device, validation_step=False, print_at=1, seed= 42):\n",
    "\n",
    "    \n",
    "    set_seed(seed)\n",
    "    for epoch in range(epochs):\n",
    "        set_seed(seed + epoch)\n",
    "        \n",
    "        prnt = (epoch % print_at) != 0 if epoch!=(epochs-1) else False\n",
    "\n",
    "\n",
    "        if not(prnt):\n",
    "            print(f\"{color.BOLD}Epoch {color.END}{epoch+1}\")\n",
    "\n",
    "        ### --> Training Phase\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "\n",
    "        \n",
    "\n",
    "        for anchor, positive, negative in tqdm(train_data_loader, disable=prnt):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "\n",
    "            e_A = model(anchor)\n",
    "            e_P = model(positive)\n",
    "            e_N = model(negative)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            loss = criterion(e_A, e_P, e_N)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss \n",
    "            train_samples += positive.size(0)\n",
    "\n",
    "\n",
    "        train_loss /= len(train_data_loader)\n",
    "        \n",
    "        if not(prnt):\n",
    "            print(f\"TRAINING   -> Loss: {train_loss:2.6f}\")\n",
    "            print(\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN WITH EARLY STOPPING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T12:56:31.978202Z",
     "start_time": "2025-02-25T12:56:31.973369Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, optimizer, criterion, train_data_loader, val_data_loader, device, \n",
    "          validation_step=False, print_at=1, early_stopping_patience=3, \n",
    "          min_delta=0.001, restore_best_weights=True, seed=42):\n",
    "    \n",
    "    set_seed(seed)\n",
    "    best_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        set_seed(seed + epoch)\n",
    "        prnt = (epoch % print_at) != 0 if epoch != (epochs-1) else False\n",
    "\n",
    "        # Inizializza early_stopping_triggered all'inizio di ogni epoch\n",
    "        early_stopping_triggered = False\n",
    "\n",
    "        if not prnt:\n",
    "            print(f\"{color.BOLD}Epoch {color.END}{epoch+1}\")\n",
    "\n",
    "        ### --> Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "\n",
    "        for anchor, positive, negative in tqdm(train_data_loader, disable=prnt):\n",
    "            optimizer.zero_grad()\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            e_A = model(anchor)\n",
    "            e_P = model(positive)\n",
    "            e_N = model(negative)\n",
    "\n",
    "            loss = criterion(e_A, e_P, e_N)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_samples += positive.size(0)\n",
    "\n",
    "        train_loss /= len(train_data_loader)\n",
    "        \n",
    "        ### --> Validation Phase (solo se richiesto)\n",
    "        val_loss = 0.0\n",
    "        if validation_step and not prnt:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for anchor, positive, negative in val_data_loader:\n",
    "                    anchor = anchor.to(device)\n",
    "                    positive = positive.to(device)\n",
    "                    negative = negative.to(device)\n",
    "\n",
    "                    e_A = model(anchor)\n",
    "                    e_P = model(positive)\n",
    "                    e_N = model(negative)\n",
    "\n",
    "                    loss = criterion(e_A, e_P, e_N)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                val_loss /= len(val_data_loader)\n",
    "\n",
    "        ### --> Early Stopping Logic\n",
    "        if validation_step and not prnt:\n",
    "            # Controlla miglioramento\n",
    "            if (best_loss - val_loss) > min_delta:\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                no_improvement_count = 0\n",
    "                # Salva lo stato del modello migliore\n",
    "                if restore_best_weights:\n",
    "                    print(\"Best epoch: \", best_epoch)\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "                if no_improvement_count >= early_stopping_patience:\n",
    "                    print(f\"\\n{color.RED}Early stopping at epoch {epoch+1}{color.END}\")\n",
    "                    early_stopping_triggered = True\n",
    "\n",
    "        ### --> Stampa risultati\n",
    "        if not prnt:\n",
    "            log_str = f\"TRAINING   -> Loss: {train_loss:2.6f}\"\n",
    "            if validation_step:\n",
    "                log_str += f\" | VALIDATION -> Loss: {val_loss:2.6f}\"\n",
    "            print(log_str)\n",
    "            print(\"\")\n",
    "\n",
    "        ### --> Interrompi il training se early stopping\n",
    "        if early_stopping_triggered:\n",
    "            break\n",
    "\n",
    "    ### --> Ripristina i migliori pesi se richiesto\n",
    "    if restore_best_weights and best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"{color.GREEN}Restored best model weights{color.END}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esecuzione del Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.161048Z",
     "start_time": "2025-02-25T12:56:32.035203Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train senza Early Stopping\n",
    "'''\n",
    "train(\n",
    "    model=distance_model,\n",
    "    epochs=100,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss,\n",
    "    train_data_loader=training_dataloader,\n",
    "    val_data_loader=None,\n",
    "    validation_step=False,\n",
    "    device=torch.device(\"cuda\"),\n",
    "    print_at=1,\n",
    "    seed=42\n",
    ")\n",
    "'''\n",
    "\n",
    "#Train con Early Stopping\n",
    "distance_model = train(\n",
    "    distance_model,\n",
    "    epochs=100,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss,\n",
    "    train_data_loader=training_dataloader,\n",
    "    val_data_loader=val_data_loader,\n",
    "    device=device,\n",
    "    validation_step=True,\n",
    "    early_stopping_patience=4,\n",
    "    min_delta=0.005,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220054Z",
     "start_time": "2025-02-25T11:56:40.068778Z"
    }
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "with open(r\"models/triplet_loss/QuantumTripletLossMNIST_MPS.pt\", \"wb\") as f:\n",
    "    torch.save(distance_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220200Z",
     "start_time": "2025-02-24T19:25:11.933418Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open(r\"models/triplet_loss/QuantumTripletLossMNIST_MPS.pt\", \"rb\") as f:\n",
    "    distance_model.load_state_dict(torch.load(f))\n",
    "distance_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220269Z",
     "start_time": "2025-02-25T11:56:40.099567Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(t, batch_size=10, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    distance_model.eval()\n",
    "    embedding_data = np.empty((0,16))\n",
    "    for anchor, _,_ in tqdm(training_dataloader):\n",
    "        anchor = anchor.to(device)\n",
    "        embedding_data = np.concatenate((embedding_data,distance_model(anchor).to(\"cpu\").squeeze(0).numpy()), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220317Z",
     "start_time": "2025-02-25T11:56:40.632494Z"
    }
   },
   "outputs": [],
   "source": [
    "#confronto tra la distanza dei dati originali e la distanza dei dati embending ottenuiti tramite il modello ibrido\n",
    "baseline_distance = metrics.pairwise_distances(t.get_flatten())\n",
    "learned_distance = metrics.pairwise_distances(embedding_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220390Z",
     "start_time": "2025-02-25T11:56:40.650554Z"
    }
   },
   "outputs": [],
   "source": [
    "quantum_clustering = AgglomerativeClustering(n_clusters=10, linkage=\"average\", metric=\"precomputed\")\n",
    "quantum_prediction = quantum_clustering.fit_predict(learned_distance)\n",
    "evaluate_clustering(embedding_data, quantum_prediction, t.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220443Z",
     "start_time": "2025-02-25T11:56:40.703125Z"
    }
   },
   "outputs": [],
   "source": [
    "quantum_clustering = KMeans(n_clusters=10,  init='k-means++', n_init=10,random_state=42)\n",
    "quantum_prediction = quantum_clustering.fit_predict(embedding_data)\n",
    "evaluate_clustering(embedding_data, quantum_prediction, t.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220508Z",
     "start_time": "2025-02-25T11:56:40.756236Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "training_dataloader = DataLoader(t, batch_size=10, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    distance_model.eval()\n",
    "    clustering_data = np.empty((0,8))\n",
    "    for anchor, _,_ in tqdm(training_dataloader):\n",
    "        x = anchor.to(device)\n",
    "        x = distance_model.conv_1(x)\n",
    "        x = distance_model.conv_2(x)\n",
    "        x = distance_model.conv_3(x)\n",
    "        x = distance_model.flatten(x)\n",
    "        x = distance_model.reduction(x)\n",
    "        clustering_data = np.concatenate((clustering_data,x.to(\"cpu\").squeeze(0).numpy()), axis=0)\n",
    "\n",
    "clustering_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220660Z",
     "start_time": "2025-02-25T11:56:40.878922Z"
    }
   },
   "outputs": [],
   "source": [
    "from qiskit import ClassicalRegister\n",
    "from qiskit.providers.basic_provider import BasicProvider\n",
    "from qiskit import transpile\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "#quantum_w è un insieme di pesi ottenuti da distance_model.q1. Viene trasformato in un array NumPy e usato nei parametri del circuito.\n",
    "#qemb_circuit è il circuito quantistico associato alla rete neurale quantistica.\n",
    "quantum_w = distance_model.q1.weight.detach().to(\"cpu\").numpy()\n",
    "qemb_circuit = distance_model.q1.neural_network.circuit\n",
    "\n",
    "def quantum_embedding_distance(x,y):\n",
    "    '''\n",
    "    base: Un registro quantistico di 8 qubit per rappresentare i dati.\n",
    "    ancilla: Un singolo qubit ausiliario necessario per lo SWAP test.\n",
    "    classical: Un registro classico per immagazzinare il risultato della misura.\n",
    "    swap_circuit: Il circuito quantistico che eseguirà il test.\n",
    "    '''\n",
    "    base = QuantumRegister(8, \"data\")\n",
    "    ancilla = QuantumRegister(1, 'ancilla')\n",
    "    classical = ClassicalRegister(1, 'output')\n",
    "    swap_circuit = QuantumCircuit(base, ancilla, classical)\n",
    "\n",
    "    '''\n",
    "    w1 e w2 sono le versioni estese dei vettori x e y, a cui vengono aggiunti i pesi quantum_w.\n",
    "    q1 e q2 sono i circuiti parametrizzati con w1 e w2, che rappresentano gli stati quantistici degli embedding.\n",
    "    '''\n",
    "    w1 = np.append(x, quantum_w)\n",
    "    w2 = np.append(y, quantum_w)\n",
    "\n",
    "    q1 = qemb_circuit.assign_parameters(w1)\n",
    "    q2 = qemb_circuit.assign_parameters(w2)\n",
    "\n",
    "    '''\n",
    "    q1 viene caricato nei primi 4 qubit del registro base.\n",
    "    q2 viene caricato nei secondi 4 qubit del registro base.\n",
    "    A questo punto, il circuito ha due stati quantistici distinti |ψ1⟩ e |ψ2⟩ caricati nei primi 4 e ultimi 4 qubit.\n",
    "    '''\n",
    "    swap_circuit = swap_circuit.compose(q1, [0,1,2,3])\n",
    "    swap_circuit = swap_circuit.compose(q2, [4,5,6,7])\n",
    "\n",
    "    # Implementazione dello SWAP test, serve per misurare la somiglianza tra i due stati quantistici |ψ1⟩ e |ψ2⟩.\n",
    "    swap_circuit.barrier()\n",
    "\n",
    "    swap_circuit.h(ancilla)\n",
    "    swap_circuit.cswap(ancilla, 0,4)\n",
    "    swap_circuit.cswap(ancilla, 1,5)\n",
    "    swap_circuit.cswap(ancilla, 2,6)\n",
    "    swap_circuit.cswap(ancilla, 3,7)\n",
    "    swap_circuit.h(ancilla)\n",
    "    # Misura l'ancilla e memorizza il risultato nel registro classico.\n",
    "    swap_circuit.measure(ancilla,classical)\n",
    "\n",
    "    backend = BasicProvider().get_backend('basic_simulator')\n",
    "    qc = transpile(swap_circuit, backend)\n",
    "    result = backend.run(qc, shots=1000).result().get_counts(qc).get('1',0)\n",
    "\n",
    "    ret = result\n",
    "    return ret\n",
    "\n",
    "\n",
    "quantum_embedding_distance(clustering_data[16], clustering_data[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sezione Test Del Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220712Z",
     "start_time": "2025-02-25T11:56:40.935963Z"
    }
   },
   "outputs": [],
   "source": [
    "t_test = MNIST_Distance_Dataset_Triplet_Loss(X_test, y_test)\n",
    "t_test_loader = DataLoader(t_test, batch_size=128, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    distance_model.eval()\n",
    "    test_embedding_data = np.empty((0,16))\n",
    "    for anchor, _,_ in tqdm(t_test_loader):\n",
    "        anchor = anchor.to(device)\n",
    "        test_embedding_data = np.concatenate((test_embedding_data, distance_model(anchor).to(\"cpu\").squeeze(0).numpy()), axis=0)\n",
    "\n",
    "reduction_model = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "reduction_model_embedding = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "\n",
    "vis_x = reduction_model.fit_transform(t_test.get_flatten())\n",
    "vis_x_embed = reduction_model_embedding.fit_transform(test_embedding_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220757Z",
     "start_time": "2025-02-25T11:57:26.060821Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"QUANTUM AGGLOMERATIVE CLUSTERING\")\n",
    "quantum_clustering = AgglomerativeClustering(n_clusters=10, linkage=\"average\")\n",
    "quantum_prediction1 = quantum_clustering.fit_predict(test_embedding_data)\n",
    "evaluate_clustering(test_embedding_data, quantum_prediction1, t_test.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220816Z",
     "start_time": "2025-02-25T11:57:27.590974Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"QUANTUM KMEANS CLUSTERING\")\n",
    "quantum_clustering = KMeans(n_clusters=10, init=\"k-means++\",n_init=10,random_state=42)\n",
    "quantum_prediction2 = quantum_clustering.fit_predict(test_embedding_data)\n",
    "evaluate_clustering(test_embedding_data, quantum_prediction2, t_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:14:49.220876Z",
     "start_time": "2025-02-25T11:57:28.174272Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize the cluserting\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "fig.suptitle(\"Data visualization using TSNE\", weight=\"bold\")\n",
    "ax[0].scatter(vis_x[:,0], vis_x[:,1], c=t_test.target[:len(vis_x)], cmap='Dark2')\n",
    "ax[0].set_title(\"Original Data\")\n",
    "ax[1].scatter(vis_x_embed[:,0], vis_x_embed[:,1], c=quantum_prediction2, cmap='Dark2')\n",
    "ax[1].set_title(\"Quantum Kmeans Clustering\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
